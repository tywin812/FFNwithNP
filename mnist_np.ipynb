{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "160cf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a635ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X = mnist.data.astype(np.float32) / 255.0\n",
    "    y = mnist.target.astype(np.int8)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d90bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data, requires_grad=False, grad_fn=\"Leaf\"):\n",
    "        self.data = data\n",
    "        self.requires_grad = requires_grad\n",
    "        self._backward = None\n",
    "        self.parents = []\n",
    "        self.grad = None\n",
    "        self.grad_fn = grad_fn\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Tensor(data={self.data}, requires_grad={self.requires_grad}, grad_fn={self.grad_fn})\"\n",
    "        \n",
    "    def backward(self, grad=None):\n",
    "        if grad is None:\n",
    "            if self.data.size == 1:\n",
    "                grad = np.ones_like(self.data)\n",
    "            else:\n",
    "                raise RuntimeError(\"grad must be specified for non-scalar tensor\")\n",
    "        self.grad = grad\n",
    "        \n",
    "        visited = set()\n",
    "        topo_order = []\n",
    "        \n",
    "        def build_topo(tensor):\n",
    "            if tensor not in visited:\n",
    "                visited.add(tensor)\n",
    "                for parent in tensor.parents:\n",
    "                    build_topo(parent)\n",
    "                topo_order.append(tensor)\n",
    "                \n",
    "        build_topo(self)\n",
    "        \n",
    "        for tensor in reversed(topo_order):\n",
    "            if tensor._backward is not None:\n",
    "                tensor._backward()\n",
    "            \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        out = Tensor(self.data + other.data, requires_grad=self.requires_grad or other.requires_grad, grad_fn=\"Add\")\n",
    "        \n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                if self.data.ndim == 0: \n",
    "                    grad_self = out.grad.sum()\n",
    "                elif self.data.ndim < out.grad.ndim:\n",
    "                    grad_self = out.grad.sum(axis=0)\n",
    "                else:\n",
    "                    grad_self = out.grad\n",
    "                self.grad = self.grad + grad_self if self.grad is not None else grad_self\n",
    "            \n",
    "            if other.requires_grad:\n",
    "                if other.data.ndim == 0: \n",
    "                    grad_other = out.grad.sum()\n",
    "                elif other.data.ndim < out.grad.ndim:\n",
    "                    grad_other = out.grad.sum(axis=0)\n",
    "                else:\n",
    "                    grad_other = out.grad\n",
    "                other.grad = other.grad + grad_other if other.grad is not None else grad_other\n",
    "        \n",
    "        out._backward = _backward\n",
    "        out.parents = [self, other]\n",
    "        return out\n",
    "        \n",
    "    def __matmul__(self, other):\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        out = Tensor(self.data @ other.data, requires_grad=self.requires_grad or other.requires_grad, grad_fn=\"MatMul\")\n",
    "        \n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad = self.grad + out.grad @ other.data.T if self.grad is not None else out.grad @ other.data.T\n",
    "            if other.requires_grad:\n",
    "                other.grad = other.grad + self.data.T @ out.grad if other.grad is not None else self.data.T @ out.grad         \n",
    "        \n",
    "        out._backward = _backward\n",
    "        out.parents = [self, other]\n",
    "        return out\n",
    "    \n",
    "    def relu(self):\n",
    "        out = Tensor(np.maximum(0, self.data), requires_grad=self.requires_grad, grad_fn=\"ReLU\")\n",
    "        \n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad = self.grad + out.grad * (out.data > 0) if self.grad is not None else out.grad * (out.data > 0)\n",
    "        \n",
    "        out._backward = _backward\n",
    "        out.parents = [self]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f9398ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = []\n",
    "\n",
    "    # def parameters(self):\n",
    "    #     return self._parameters\n",
    "\n",
    "    def parameters(self):\n",
    "        params = list(self._parameters)\n",
    "        for attr in self.__dict__.values():\n",
    "            if isinstance(attr, Module):\n",
    "                params += attr.parameters()\n",
    "            elif isinstance(attr, list) or isinstance(attr, tuple):\n",
    "                for item in attr:\n",
    "                    if isinstance(item, Module):\n",
    "                        params += item.parameters()\n",
    "        return params\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def train(self):\n",
    "        for attr in self.__dict__.values():\n",
    "            if isinstance(attr, Module):\n",
    "                attr.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for attr in self.__dict__.values():\n",
    "            if isinstance(attr, Module):\n",
    "                attr.eval()\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = Tensor(np.random.randn(in_features, out_features) * np.sqrt(2. / in_features), requires_grad=True)\n",
    "        self.bias = Tensor(np.zeros(out_features), requires_grad=True)\n",
    "        self._parameters = [self.weight, self.bias]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.weight + self.bias\n",
    "    \n",
    "class ReLU(Module):\n",
    "    def forward(self, x):\n",
    "        return x.relu()\n",
    "    \n",
    "class Sequential(Module):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for layer in layers:\n",
    "            self._parameters.extend(layer.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def train(self):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'train'):\n",
    "                layer.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'eval'):\n",
    "                layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a3f2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, parameters, lr=0.01):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            if p.grad is not None:\n",
    "                p.data -= self.lr * p.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cb21167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(Module):\n",
    "    def __init__(self, num_features, momentum=0.1, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = Tensor(np.ones(num_features), requires_grad=True)\n",
    "        self.beta = Tensor(np.zeros(num_features), requires_grad=True)\n",
    "        self.running_mean = Tensor(np.zeros(num_features), requires_grad=False)\n",
    "        self.running_var = Tensor(np.ones(num_features), requires_grad=False)\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.training = True\n",
    "        self._parameters = [self.gamma, self.beta]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mean = x.data.mean(axis=0)\n",
    "            var = x.data.var(axis=0)\n",
    "            x_norm = (x.data - mean) / np.sqrt(var + self.epsilon)\n",
    "            out_data = self.gamma.data * x_norm + self.beta.data\n",
    "            self.running_mean.data = self.momentum * mean + (1 - self.momentum) * self.running_mean.data\n",
    "            self.running_var.data = self.momentum * var + (1 - self.momentum) * self.running_var.data \n",
    "            out = Tensor(out_data, requires_grad=True, grad_fn=\"BatchNorm\")\n",
    "            out.parents = [x, self.gamma, self.beta]\n",
    "            out._backward = lambda: self._backward(out, x, mean, var)\n",
    "            return out\n",
    "        else:\n",
    "            x_norm = (x.data - self.running_mean.data) / np.sqrt(self.running_var.data + self.epsilon)\n",
    "            out_data = self.gamma.data * x_norm + self.beta.data\n",
    "            return Tensor(out_data)\n",
    "\n",
    "    def _backward(self, out, x, mean, var):\n",
    "        N = x.data.shape[0]\n",
    "        x_norm = (x.data - mean) / np.sqrt(var + self.epsilon)\n",
    "        dgamma = np.sum(out.grad * x_norm, axis=0)\n",
    "        dbeta = np.sum(out.grad, axis=0)\n",
    "        dx_norm = out.grad * self.gamma.data\n",
    "        dvar = np.sum(dx_norm * (x.data - mean) * -0.5 / (var + self.epsilon)**1.5, axis=0)\n",
    "        dmean = np.sum(dx_norm * -1 / np.sqrt(var + self.epsilon), axis=0) + dvar * np.sum(-2 * (x.data - mean), axis=0) / N\n",
    "        dx = dx_norm / np.sqrt(var + self.epsilon) + dvar * 2 * (x.data - mean) / N + dmean / N\n",
    "        \n",
    "        if x.requires_grad:\n",
    "            x.grad = x.grad + dx if x.grad is not None else dx\n",
    "        if self.gamma.requires_grad:\n",
    "            self.gamma.grad = self.gamma.grad + dgamma if self.gamma.grad is not None else dgamma\n",
    "        if self.beta.requires_grad:\n",
    "            self.beta.grad = self.beta.grad + dbeta if self.beta.grad is not None else dbeta\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea78b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        max_val = np.max(inputs.data, axis=self.dim, keepdims=True)\n",
    "        logsumexp = np.log(np.sum(np.exp(inputs.data - max_val), axis=self.dim, keepdims=True)) + max_val\n",
    "        log_probs = inputs.data - logsumexp\n",
    "        batch_size = inputs.data.shape[0]\n",
    "        targets = targets.data.astype(int) if isinstance(targets, Tensor) else targets.astype(int)\n",
    "        loss = -np.mean(log_probs[np.arange(batch_size), targets])\n",
    "        out = Tensor(loss, requires_grad=inputs.requires_grad, grad_fn=\"CrossEntropyLoss\")\n",
    "        out.parents = [inputs]\n",
    "        out._backward = lambda: self._backward(out, inputs, log_probs, targets)\n",
    "        return out\n",
    "\n",
    "    def _backward(self, out, inputs, log_probs, targets):\n",
    "        if inputs.requires_grad:\n",
    "            batch_size = inputs.data.shape[0]\n",
    "            grad = np.exp(log_probs) \n",
    "            grad[np.arange(batch_size), targets] -= 1\n",
    "            grad /= batch_size\n",
    "            inputs.grad = inputs.grad + grad if inputs.grad is not None else grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1fc1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    for start in range(0, num_samples, batch_size):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "        batch_indices = indices[start:end]\n",
    "        yield X[batch_indices], y[batch_indices]\n",
    "        \n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def compute_f1_scores(y_true, y_pred, num_classes=10):\n",
    "    f1_scores = np.zeros(num_classes)\n",
    "    for class_idx in range(num_classes):\n",
    "        tp = np.sum((y_pred == class_idx) & (y_true == class_idx))\n",
    "        fp = np.sum((y_pred == class_idx) & (y_true != class_idx))\n",
    "        fn = np.sum((y_pred != class_idx) & (y_true == class_idx))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        \n",
    "        if precision + recall > 0:\n",
    "            f1_scores[class_idx] = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1_scores[class_idx] = 0.0\n",
    "    \n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5baa1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(784, 128)\n",
    "        self.bn1 = BatchNorm(128)\n",
    "        self.fc2 = Linear(128, 128)\n",
    "        self.bn2 = BatchNorm(128)\n",
    "        self.fc3 = Linear(128, 64)\n",
    "        self.bn3 = BatchNorm(64)\n",
    "        self.fc4 = Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = out.relu()\n",
    "\n",
    "        identity = out  \n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = out.relu()\n",
    "        out = out + identity\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = out.relu()\n",
    "\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b65baaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.8437, Val Loss: 0.4737, Accuracy: 0.8876\n",
      "F1 Scores per class: [0.93485342 0.95213115 0.88833747 0.87568413 0.85951787 0.83360522\n",
      " 0.9047195  0.91997116 0.85313531 0.83443709]\n",
      "Epoch 2/10, Train Loss: 0.3926, Val Loss: 0.3309, Accuracy: 0.9186\n",
      "F1 Scores per class: [0.95616883 0.96483079 0.91762768 0.90483619 0.90225564 0.88907015\n",
      " 0.92940125 0.93342981 0.89067524 0.8855472 ]\n",
      "Epoch 3/10, Train Loss: 0.2968, Val Loss: 0.2702, Accuracy: 0.9329\n",
      "F1 Scores per class: [0.96025953 0.97279363 0.93137255 0.92307692 0.91896408 0.90894176\n",
      " 0.94181818 0.94075145 0.91283677 0.90833333]\n",
      "Epoch 4/10, Train Loss: 0.2494, Val Loss: 0.2329, Accuracy: 0.9395\n",
      "F1 Scores per class: [0.95934959 0.97480106 0.94069862 0.92789969 0.93153001 0.91461412\n",
      " 0.94275492 0.95293266 0.92515924 0.91576314]\n",
      "Epoch 5/10, Train Loss: 0.2177, Val Loss: 0.2086, Accuracy: 0.9463\n",
      "F1 Scores per class: [0.96674777 0.97612732 0.94796748 0.94126739 0.93456376 0.93211921\n",
      " 0.9520362  0.95086705 0.92776886 0.92666667]\n",
      "Epoch 6/10, Train Loss: 0.1951, Val Loss: 0.1929, Accuracy: 0.9481\n",
      "F1 Scores per class: [0.96495518 0.97810219 0.94890511 0.94720497 0.93198992 0.93377483\n",
      " 0.94936709 0.95971223 0.93566322 0.92191436]\n",
      "Epoch 7/10, Train Loss: 0.1791, Val Loss: 0.1813, Accuracy: 0.9511\n",
      "F1 Scores per class: [0.96440129 0.97813121 0.95299838 0.94744977 0.93389121 0.94166667\n",
      " 0.95471014 0.96092619 0.94342629 0.92527288]\n",
      "Epoch 8/10, Train Loss: 0.1649, Val Loss: 0.1695, Accuracy: 0.9529\n",
      "F1 Scores per class: [0.96045198 0.98143236 0.95883777 0.94875776 0.93299406 0.94127378\n",
      " 0.95401262 0.96322999 0.94711538 0.93132328]\n",
      "Epoch 9/10, Train Loss: 0.1537, Val Loss: 0.1612, Accuracy: 0.9567\n",
      "F1 Scores per class: [0.95948136 0.98215466 0.95928339 0.95987654 0.93829248 0.95348837\n",
      " 0.95927602 0.96023138 0.95131684 0.93588676]\n",
      "Epoch 10/10, Train Loss: 0.1444, Val Loss: 0.1535, Accuracy: 0.9560\n",
      "F1 Scores per class: [0.96590909 0.98143236 0.96091205 0.95296839 0.94304858 0.94342762\n",
      " 0.95754291 0.96248196 0.95047923 0.93467337]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val = load_mnist()\n",
    "\n",
    "# model = Sequential(\n",
    "#     Linear(784, 128),\n",
    "#     BatchNorm(128),\n",
    "#     ReLU(),\n",
    "#     Linear(128, 64),\n",
    "#     BatchNorm(64),\n",
    "#     ReLU(),\n",
    "#     Linear(64, 10)\n",
    "# )\n",
    "\n",
    "model = CustomNet()\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in get_batches(X_train, y_train, batch_size):\n",
    "        X_batch = Tensor(X_batch)\n",
    "        y_batch = Tensor(y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data * X_batch.data.shape[0]\n",
    "    train_loss /= X_train.shape[0]\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for X_batch, y_batch in get_batches(X_val, y_val, batch_size):\n",
    "        X_batch = Tensor(X_batch)\n",
    "        y_batch = Tensor(y_batch)\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        val_loss += loss.data * X_batch.data.shape[0]\n",
    "        preds = np.argmax(outputs.data, axis=1)\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y_batch.data)\n",
    "    val_loss /= X_val.shape[0]\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    accuracy = compute_accuracy(y_true, y_pred)\n",
    "    f1 = compute_f1_scores(y_true, y_pred, num_classes=10)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(\"F1 Scores per class:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58855a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f201498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9562857142857143\n",
      "Test F1 Scores per class: [0.98168498 0.97755611 0.95619896 0.93762311 0.95346939 0.95216401\n",
      " 0.96759941 0.95961003 0.94289898 0.93351611]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for X_batch, y_batch in get_batches(X_test, y_test, batch_size):\n",
    "    X_batch = Tensor(X_batch)\n",
    "    y_batch = Tensor(y_batch)\n",
    "    outputs = model(X_batch)\n",
    "    preds = np.argmax(outputs.data, axis=1)\n",
    "    y_pred.extend(preds)\n",
    "    y_true.extend(y_batch.data)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "test_accuracy = compute_accuracy(y_true, y_pred)\n",
    "test_f1 = compute_f1_scores(y_true, y_pred, num_classes=10)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test F1 Scores per class:\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "209ba0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Forward ===\n",
      "\n",
      "Layer 0 output:\n",
      "  Data: [[ 0.26484162  1.45450663 -0.10524285]\n",
      " [-0.82111716  0.20697457  1.2012897 ]]\n",
      "  requires_grad: True\n",
      "  grad_fn: Add\n",
      "  Parents: ['Tensor(data=(2, 3), requires_grad=True, grad_fn=MatMul)', 'Tensor(data=(3,), requires_grad=True, grad_fn=Leaf)']\n",
      "\n",
      "Layer 1 output:\n",
      "  Data: [[0.26484162 1.45450663 0.        ]\n",
      " [0.         0.20697457 1.2012897 ]]\n",
      "  requires_grad: True\n",
      "  grad_fn: ReLU\n",
      "  Parents: ['Tensor(data=(2, 3), requires_grad=True, grad_fn=Add)']\n",
      "\n",
      "Layer 2 output:\n",
      "  Data: [[ 0.47453982 -0.74005497]\n",
      " [ 2.37237096 -1.55193448]]\n",
      "  requires_grad: True\n",
      "  grad_fn: Add\n",
      "  Parents: ['Tensor(data=(2, 2), requires_grad=True, grad_fn=MatMul)', 'Tensor(data=(2,), requires_grad=False, grad_fn=Leaf)']\n",
      "\n",
      "Layer 3 output:\n",
      "  Data: [[0.47453982 0.        ]\n",
      " [2.37237096 0.        ]]\n",
      "  requires_grad: True\n",
      "  grad_fn: ReLU\n",
      "  Parents: ['Tensor(data=(2, 2), requires_grad=True, grad_fn=Add)']\n",
      "\n",
      "Layer 4 output:\n",
      "  Data: [[ 0.02171424 -0.08882619]\n",
      " [ 0.10855618 -0.44406953]]\n",
      "  requires_grad: True\n",
      "  grad_fn: Add\n",
      "  Parents: ['Tensor(data=(2, 2), requires_grad=True, grad_fn=MatMul)', 'Tensor(data=(2,), requires_grad=True, grad_fn=Leaf)']\n",
      "\n",
      "Loss value: 0.8232809611874268\n",
      "Loss requires_grad: True\n",
      "Output requires_grad: True\n",
      "Output data: [[ 0.02171424 -0.08882619]\n",
      " [ 0.10855618 -0.44406953]]\n",
      "\n",
      "=== Проверка градиентов ===\n",
      "\n",
      "Layer 0 (Linear):\n",
      "  Weight requires_grad: True\n",
      "  Weight grad exists: True\n",
      "  Bias requires_grad: True\n",
      "  Bias grad exists: True\n",
      "\n",
      "Layer 1 (ReLU):\n",
      "  Input requires_grad: True\n",
      "  Input grad exists: True\n",
      "  Input grad: [[ 0.11468996 -0.03883374 -0.        ]\n",
      " [-0.          0.05218009  0.13700952]]\n",
      "\n",
      "Layer 2 (Linear):\n",
      "  Weight requires_grad: False\n",
      "  Weight grad exists: False\n",
      "  Bias requires_grad: False\n",
      "  Bias grad exists: False\n",
      "\n",
      "Layer 3 (ReLU):\n",
      "  Input requires_grad: True\n",
      "  Input grad exists: True\n",
      "  Input grad: [[-0.05502017 -0.        ]\n",
      " [ 0.07392945  0.        ]]\n",
      "\n",
      "Layer 4 (Linear):\n",
      "  Weight requires_grad: True\n",
      "  Weight grad exists: True\n",
      "  Bias requires_grad: True\n",
      "  Bias grad exists: True\n",
      "\n",
      "Input X:\n",
      "  requires_grad: True\n",
      "  grad exists: True\n",
      "\n",
      "Output grad (from CrossEntropyLoss):\n",
      "  grad exists: True\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randn(2, 4)  \n",
    "y = np.array([0,1])       \n",
    "\n",
    "model = Sequential(\n",
    "    Linear(4, 3),  \n",
    "    ReLU(),\n",
    "    Linear(3, 2),   \n",
    "    ReLU(),\n",
    "    Linear(2, 2)    \n",
    ")\n",
    "\n",
    "for param in model.layers[2].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# for param in model.layers[4].parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.layers[0].parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "X_tensor = Tensor(X, requires_grad=True)\n",
    "y_tensor = Tensor(y)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "print(\"=== Forward ===\")\n",
    "intermediate_outputs = [X_tensor]\n",
    "x = X_tensor\n",
    "for i, layer in enumerate(model.layers):\n",
    "    x = layer(x)\n",
    "    intermediate_outputs.append(x)\n",
    "    print(f\"\\nLayer {i} output:\")\n",
    "    print(f\"  Data: {x.data}\")\n",
    "    print(f\"  requires_grad: {x.requires_grad}\")\n",
    "    print(f\"  grad_fn: {x.grad_fn}\")\n",
    "    print(f\"  Parents: {[f'Tensor(data={p.data.shape}, requires_grad={p.requires_grad}, grad_fn={p.grad_fn})' for p in x.parents]}\")\n",
    "\n",
    "outputs = x\n",
    "loss = criterion(outputs, y_tensor)\n",
    "print(f\"\\nLoss value: {loss.data}\")\n",
    "print(f\"Loss requires_grad: {loss.requires_grad}\")\n",
    "print(f\"Output requires_grad: {outputs.requires_grad}\")\n",
    "print(f\"Output data: {outputs.data}\")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\n=== Проверка градиентов ===\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, Linear):\n",
    "        print(f\"\\nLayer {i} (Linear):\")\n",
    "        print(f\"  Weight requires_grad: {layer.weight.requires_grad}\")\n",
    "        print(f\"  Weight grad exists: {layer.weight.grad is not None}\")\n",
    "        print(f\"  Bias requires_grad: {layer.bias.requires_grad}\")\n",
    "        print(f\"  Bias grad exists: {layer.bias.grad is not None}\")\n",
    "    elif isinstance(layer, ReLU):\n",
    "        print(f\"\\nLayer {i} (ReLU):\")\n",
    "        print(f\"  Input requires_grad: {intermediate_outputs[i].requires_grad}\")\n",
    "        print(f\"  Input grad exists: {intermediate_outputs[i].grad is not None}\")\n",
    "        print(f\"  Input grad: {intermediate_outputs[i].grad}\")\n",
    "\n",
    "print(\"\\nInput X:\")\n",
    "print(f\"  requires_grad: {X_tensor.requires_grad}\")\n",
    "print(f\"  grad exists: {X_tensor.grad is not None}\")\n",
    "\n",
    "print(\"\\nOutput grad (from CrossEntropyLoss):\")\n",
    "print(f\"  grad exists: {outputs.grad is not None}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
